write.csv(test, "/Users/nancyorgan/Desktop/test.csv", row.names = FALSE)
table(test$id, test$event, test$site)
test = read.csv("/Users/nancyorgan/Desktop/test.csv")
test = test %>%
group_by(site, id) %>%
mutate(index = c(1:length(site))) %>%
ungroup() %>%
arrange(site, event, id)
write.csv(test, "/Users/nancyorgan/Desktop/test_new.csv", row.names = FALSE)
table(test$id, test$event, test$site)
pnorm(1, 0, 1)
qnorm(1, 0, 1)
qnorm(0)
pnorm(0)
pnorm(-1, 0, 1)
pnorm(4/5, 36, 5)
pnorm(40, 36, 5)
pnorm(40, 36, 5) - pnorm(30, 36, 5)
4/5
.2/.25
.4 *.002 + .6*.0024
.4*.002
.4*.002/.00224
.001/.0022
.001/.00224
.0008/.00224
sqrt(125*.56*.44)
.6*125
pnorm(75, .56*125, 5.55)
pnorm(75, .56*125, 5.55) - .5
sqrt(.56*.44/125)
sd = sqrt(.56*.44/125)
pnorm(75, .56*125,sd) - .5
125*sqrt(.56*.44/125)
sd = 5.549775
.56*235
.56*125
pnorm(75, 70, sd)
pnorm(75, 70, sd) - .50
sd = sqrt(.56*.44/125)
sd
pnorm(.6, .56, sd)
pnorm(.6, .56, sd) - pnorm(.50, .56, sd)
pnorm(.6*125, .56*125, sd*125) - pnorm(.50*125, .56,*125, sd*125)
pnorm(.6*125, .56*125, sd*125) - pnorm(.50*125, .56*125, sd*125)
20/35
750-680
pnorm(750, 680, 35) - pnorm(700, 680, 35)
pnorm(700, 680, 35)
1- pnorm(700, 680, 35)
1- pnorm(750, 680, 35)
.20*260
68-52
.05*250
.05*220
.03*220
.2*5
40/220
220 + 4(c(1:10))
220 + 4*c(1:10)
220 + 3*c(1:10)
220 + 3*c(1:15)
.2*255
68-51
220 + 3*c(1:20)
220 + 3*c(1:15)
.34 + .45 - .34*45
.34 + .45 - .34*.45
1.37
11*(1-.37)
.28 + 2*.15 + 3*.11 + 4*.08 + 5*.06
.18*(1-.15)
85*18/100
18/85
5/38
pnorm(0, 1, 1)
pnorm(0, 1, 0)
pnorm(0, 0, 1)
pnorm(2, 0, 1)
pnorm(1, 0, 1)
pnorm(.86, 0, 1)
qnorm(.80, 0, 1)
2.2*qnorm(.80, 0, 1)
9.1 - 2.2*qnorm(.80, 0, 1)
.1/.4
.1/.5
porm(0, 5, sqrt(52))
pnorm(0, 5, sqrt(52))
1 - pnorm(0, 5, sqrt(52))
pnorm(.5, .4, .5)
1 - pnorm(.5, .4, .5)
1 - pnorm(.5, .4, .05)
5*4*3
10*9*8
60/720
sqrt(268)
268/4
sqrt(260^2 + 390^2)
1340 + 850
.27^2
(25*87 + 30*98)/55
11 + 13.928*13
11 + 13.928*3
130 + 10 + .2*130 + 22 + 5
130 + 10 + 5
145/2
60-42
59-40
data(iris)
head(iris)
dim(iris)
write.csv(subset(iris, select = c("Sepal.Length", "Sepal.Width")), row.names = FALSE)
iris$Sepal.Length = iris$Sepal.Length + rnorm(rnorm(150, .2, .2))
write.csv(subset(iris, select = c("Sepal.Length", "Sepal.Width")), row.names = FALSE)
iris$Sepal.Length = round(iris$Sepal.Length + rnorm(rnorm(150, .2, .2)), 3)
write.csv(subset(iris, select = c("Sepal.Length", "Sepal.Width")), row.names = FALSE)
iris$Sepal.Length = round(iris$Sepal.Length + rnorm(rnorm(150, .2, .2)), 2)
data(iris)
head(iris)
dim(iris)
iris$Sepal.Length = round(iris$Sepal.Length + rnorm(rnorm(150, .2, .2)), 2)
iris$Sepal.Width = round(iris$Sepal.Width + rnorm(rnorm(150, .2, .2)), 2)
write.csv(subset(iris, select = c("Sepal.Length", "Sepal.Width")), row.names = FALSE)
expand.grid(c(1:20), c(1:20)
expand.grid(c(1:20), c(1:20)
)
expand.grid(c(1:20), c(1:20))
data.frame(expand.grid(c(1:20), c(1:20)),
density = rnorm(400, 5, 2) + seq(0, 4, length.out = 400))
write.csv(data.frame(expand.grid(c(1:20), c(1:20)),
density = rnorm(400, 5, 2) + seq(0, 4, length.out = 400)), row.names = FALSE)
c(500.00,
216.00,
40.00,
150.72,
241.92,
50.00,
300.00,
216.00,
320.00,
1237.50,
412.50,
412.50,
125.00,
180.00,
64.00)
this - c(500.00,
216.00,
40.00,
150.72,
241.92,
50.00,
300.00,
216.00,
320.00,
1237.50,
412.50,
412.50,
125.00,
180.00,
64.00)
this = c(500.00,
216.00,
40.00,
150.72,
241.92,
50.00,
300.00,
216.00,
320.00,
1237.50,
412.50,
412.50,
125.00,
180.00,
64.00)
sum(this)
5000 -14463.18
8.2 + 5
5 + 6.6
5 + 7.7
4.9 + 7.4
8000/1329
8000/1329*50
53-12
41/12
178/12
178/2
89/12
18500 - 1772.11
(18500 - 1772.11)/65000
.15*417
728 + 321
protein = 15 + 15 + 20 + 20 + 20 + 25 + 5*25
fats = 7*5 + 15
carbs = 115
protein
fats
protein
protein = 15 + 15 + 20 + 20 + 20 + 25 + 5*5
fats = 7*5 + 15
carbs = 115
protein
fats = 7*5 + 15
carbs = 115
fats
carbs
paste0("protein: ", sum(15 + 15 + 20 + 20 + 20 + 25 + 5*5))
paste0("carbs:  ", sum(115))
paste0("protein: ", sum(15 + 15 + 20 + 20 + 20 + 25 + 5*5))
paste0("fats: ", sum(7*5 + 15))
paste0("carbs:  ", sum(115))
paste0("fats: ", sum(3*5 + 7.5*5))
sum(1 + 1)
sum(1 + 1 + 5)
paste0("protein: ", sum(15 + 15 + 20 + 20 + 20 + 5*5 + 25))
paste0("fats: ", sum(3*5 + 7*5))
paste0("carbs:  ", sum(25 + 25 + 15 + 50))
paste0("protein: ", sum(15 + 15 + 20 + 20 + 20 + 10*5))
paste0("fats: ", sum(3*5 + 7*5))
paste0("carbs:  ", sum(115))
paste0("protein: ", sum(15 + 15 + 20 + 20 + 20 + 5*5 + 25))
paste0("fats: ", sum(3*5 + 7*5))
paste0("carbs:  ", sum(25 + 25 + 15 + 50))
paste0("protein: ", sum(15 + 15 + 20 + 20 + 20 + 10*5))
paste0("fats: ", sum(3*5 + 7*3 + 15*2))
paste0("carbs:  ", sum(10*5))
paste0("protein: ", sum(15 + 15 + 20 + 20 + 20 + 5*5 + 25))
paste0("fats: ", sum(3*5 + 7*5))
paste0("carbs:  ", sum(25 + 25 + 15 + 50))
paste0("protein: ", sum(15 + 15 + 20 + 20 + 20 + 10*5))
paste0("fats: ", sum(7*5 + 7*3 + 15*2))
paste0("carbs:  ", sum(10*5))
paste0("protein: ", sum(15 + 15 + 20 + 20 + 20 + 5*5 + 25))
paste0("fats: ", sum(3*5 + 7*2))
paste0("carbs:  ", sum(25 + 25 + 15 + 50))
paste0("protein: ", sum(15 + 15 + 20 + 20 + 20 + 10*5))
paste0("fats: ", sum(7*5 + 7*4))
paste0("carbs:  ", sum(10*5))
paste0("protein: ", sum(20 + 20 + 20 + 25 + 25 + 25 + 5))
paste0("fats: ", sum(3 + 7))
paste0("carbs:  ", sum(25 + 25 + 15 + 50))
paste0("protein: ", sum(25 + 25 + 25 + 30 + 30 + 5))
paste0("fats: ", sum(3 + 7))
paste0("carbs:  ", sum(10*5))
140*4 + 29*9 + 115*4
143*4 + 146*4 + 55*9
143.3*4 + 146.5*4 + 55.2*9
140*4 + 50*9 + 115*4
140*4/1470
50*9/1470
115*4/1470
7/10
16*2.5
4.5*2.5
13*5
3.5*5
13*4
28*2
7*6
3.5*6
5*15
23*3
4.5*3
5*13
23*5
12*5
50/30
67/45
90/60
253/5
253/55
94000*(5.5/4)
94000*(5.5/4)
1328*5.5
94000*(5.5/4.5)
253*(5.5/4.5)
write.csv(diamonds, "/Users/nancyorgan/Desktop/diamonds.csv", row.names = FALSE)
data(diamonds)
library("ggplot2")
write.csv(diamonds, "/Users/nancyorgan/Desktop/diamonds.csv", row.names = FALSE)
150 + 180 + 110
.85*1099
?geom_boxplot
library('ggplot2')
?geom_boxplot
?median
library("reshape2")
?melt
is.na(4)
is.na(NA)
!is.na(NA)
?geom_bar
.7*119
brfssdata=read.csv("https://github.com/cazvan/599B_Final/raw/master/brfss.csv")
brfssdata=read.csv("https://github.com/cazvan/599B_Final/raw/master/brfss.csv")
brfssdata$stab=as.character(brfssdata$stab) #convert stab into numeric
bad=unique(brfssdata$stab[(brfssdata$ex2014 == 0 & brfssdata$ex2016 == 1)]) #create a list of the bad states
bad # show us the bad states
dfmelt=brfssdata%>% #use main dataset
select(year, stab, mental, ex2014)%>% #select these 4 variables for use
filter(stab %nin% bad)%>% # filter out bad states
filter(!is.na(ex2014))%>% #filter out n/a responses for ex2014 variable
group_by(year,ex2014)%>% # group responeses by year then ex2014
mutate(mentavg=mean(mental, na.rm = TRUE))%>% #create a new variable that is the average number of negative mental health days for each group created above
ungroup()%>% # ungroup the groups
select(year, ex2014,mentavg)%>% #select the year, ex2014, and newly created mentavg variables
unique()%>% #only look at unique responses
mutate(ex2014=ifelse(ex2014==0, "No Expansion", "Expansion")) #change the binary reponses to string responses
library("dplyr")
dfmelt=brfssdata%>% #use main dataset
select(year, stab, mental, ex2014)%>% #select these 4 variables for use
filter(stab %nin% bad)%>% # filter out bad states
filter(!is.na(ex2014))%>% #filter out n/a responses for ex2014 variable
group_by(year,ex2014)%>% # group responeses by year then ex2014
mutate(mentavg=mean(mental, na.rm = TRUE))%>% #create a new variable that is the average number of negative mental health days for each group created above
ungroup()%>% # ungroup the groups
select(year, ex2014,mentavg)%>% #select the year, ex2014, and newly created mentavg variables
unique()%>% #only look at unique responses
mutate(ex2014=ifelse(ex2014==0, "No Expansion", "Expansion")) #change the binary reponses to string responses
library("Hmisc")
dfmelt=brfssdata%>% #use main dataset
select(year, stab, mental, ex2014)%>% #select these 4 variables for use
filter(stab %nin% bad)%>% # filter out bad states
filter(!is.na(ex2014))%>% #filter out n/a responses for ex2014 variable
group_by(year,ex2014)%>% # group responeses by year then ex2014
mutate(mentavg=mean(mental, na.rm = TRUE))%>% #create a new variable that is the average number of negative mental health days for each group created above
ungroup()%>% # ungroup the groups
select(year, ex2014,mentavg)%>% #select the year, ex2014, and newly created mentavg variables
unique()%>% #only look at unique responses
mutate(ex2014=ifelse(ex2014==0, "No Expansion", "Expansion")) #change the binary reponses to string responses
show_col(c("blue", "green"))
library("scales")
show_col(c("blue", "green"))
show_col(c("blue", "green", "red"))
library("ggplot2")
theme_bw
scale_fill_continuous
?seq.Date
seq(as.Date("2019/1/1"), as.Date("2019/12/31"), "days")
read.csv("/Users/nancyorgan/Documents/Blog/washington_weather.csv")
wash = read.csv("/Users/nancyorgan/Documents/Blog/washington_weather.csv")
wash = read.csv("/Users/nancyorgan/Documents/Blog/washington_weather.csv")
head(wash)
unique(wash$STATION)
library("e1071")
library("rgl")
install.packages("misc3d")
library(misc3d)
install.packages("rgb")
install.packages("Rgb")
library("e1071")
library("Rgl")
library("misc3d")
set.seed(87)
library("Rgb")
library("misc3d")
set.seed(87)
xss = c(rnorm(50,4,.8),seq(2,7,length=50),rnorm(50,1,1.5))
yss = c(rnorm(50,4,2),rnorm(40,7,.8),rnorm(10,5,1.5),rnorm(50,1,1.5))
zss = c(rnorm(50,4,.7),rnorm(40,7,.8),rnorm(10,5,1.5),rnorm(50,3,1.5))
category = as.integer(rep(c(6,4,3),each=50))
mydata = data.frame(category,xss,yss,zss)
plot3d(mydata[,-1],col=rep(c(6,4,3),each=50),type="s",radius=.3,
xlab="x",ylab="y",zlab="z",axes=TRUE)
install.packages("plot3D")
library("plot3D")
set.seed(87)
xss = c(rnorm(50,4,.8),seq(2,7,length=50),rnorm(50,1,1.5))
yss = c(rnorm(50,4,2),rnorm(40,7,.8),rnorm(10,5,1.5),rnorm(50,1,1.5))
zss = c(rnorm(50,4,.7),rnorm(40,7,.8),rnorm(10,5,1.5),rnorm(50,3,1.5))
category = as.integer(rep(c(6,4,3),each=50))
mydata = data.frame(category,xss,yss,zss)
plot3d(mydata[,-1],col=rep(c(6,4,3),each=50),type="s",radius=.3,
xlab="x",ylab="y",zlab="z",axes=TRUE)
??plot3d
library("plot3D")
plot3d(mydata[,-1],col=rep(c(6,4,3),each=50),type="s",radius=.3,
xlab="x",ylab="y",zlab="z",axes=TRUE)
plot3D(mydata[,-1],col=rep(c(6,4,3),each=50),type="s",radius=.3,
xlab="x",ylab="y",zlab="z",axes=TRUE)
??plot3d
install.packages("rgl")
library("rgl")
install.packages("rgl")
library("e1071")
library("rgl")
library("misc3d")
set.seed(87)
xss = c(rnorm(50,4,.8),seq(2,7,length=50),rnorm(50,1,1.5))
yss = c(rnorm(50,4,2),rnorm(40,7,.8),rnorm(10,5,1.5),rnorm(50,1,1.5))
zss = c(rnorm(50,4,.7),rnorm(40,7,.8),rnorm(10,5,1.5),rnorm(50,3,1.5))
category = as.integer(rep(c(6,4,3),each=50))
mydata = data.frame(category,xss,yss,zss)
rgl::plot3d(mydata[,-1],col=rep(c(6,4,3),each=50),type="s",radius=.3,
xlab="x",ylab="y",zlab="z",axes=TRUE)
library("rgl")
library("e1071")
library("rgl")
#write.csv(narsData, "/Users/nancyorgan/Documents/Nail-Polish/narsData.csv", row.names = FALSE)
######################################################################
######################################################################
essie = function(url){
groups = c("sheers", "whites", "nudes", "pinks", "corals", "reds", "purples",
"blues", "greens", "yellows", "grays", "metallics-and-glitters")
allData = list()
for(i in 1:length(groups)){
webpage = read_html(paste0(url, groups[i], "?selectedProduct=0") )
names = webpage %>% html_nodes('h3') %>% html_nodes('span')
names = gsub("<span>", "", names)
names = gsub("</span>", "", names)
colors = webpage %>%
html_nodes(css = "div.product-list-item__image") %>%
html_nodes("img") %>%
html_attr("src")
palette = NULL
for(j in 1:length(colors)){
tryCatch(
expr = {
temp.file = tempfile(fileext = ".jpg")
download.file(paste0("https://www.essie.com/", colors[j]), destfile = temp.file)
img <- jpeg::readJPEG(temp.file)
display_image(img)
# scales::show_col(image_palette(img, n=10))
palette[j] = image_palette(img, n=1)
unlink(temp.file)
},
error = function(e){
message("* Caught an error on itertion ", j)
print(e)
}
)
}
allData[[i]] = data.frame(group = groups[i], name = names, palette = palette)
}
allData = rbindlist(allData)
return(allData)
}
library('rvest')
library("e1071")
library("rgl")
library("misc3d")
library("data.table")
library("RImagePalette")
library("png")
library("magick")
library("jpeg")
library("dplyr")
# install_github("andreacirilloac/paletter")
url <- list(
Revlon = 'https://www.revlon.com/nails/nail-color/revlon-nail-enamel?shade=adventurous',
Maybelline = 'https://www.maybelline.com.au/nail-makeup/nail-color/color-show-60-seconds-nail-lacquer/',
Maybelline2 = 'https://www.maybelline.com.au/nail-makeup/nail-color/super-stay-7-days',
NARS = 'https://www.narscosmetics.com/USA/milos-nail-polish/0607845036456.html?gclid=Cj0KCQjwl8XtBRDAARIsAKfwtxBiqFJw74nAgsr_bolu-Uojx7H7jBq-E6rET3DwUlBgaMudndeL96EaAkBtEALw_wcB&gclsrc=aw.ds',
Essie = 'https://www.essie.com/nail-polish/by-color/',
Dior = 'https://www.dior.com/en_us/products/beauty-Y0002959_F000355257-dior-vernis-couture-color-gel-shine-long-wear-nail-lacquer?gclid=Cj0KCQjwl8XtBRDAARIsAKfwtxAvCXrpqEGt2MfLk3Ta3xJMNDGAExmKGCkqlJ_RYPl-16DUg58BdpwaAj1pEALw_wcB&gclsrc=aw.ds',
Chanel = 'https://www.chanel.com/us/makeup/p/159705/le-vernis-longwear-nail-colour/',
YSL = 'https://www.yslbeautyus.com/makeup/nails/la-laque-couture/1023YSL.html',
YSL2 = "https://www.yslbeautyus.com/makeup/nails/la-laque-couture-fall-look-2019/113YSL.html?cgid=makeup-nails&dwvar_113YSL_color=118%20-%20Marron%20Sulfureux#start=3&cgid=makeup-nails",
Urban = 'https://www.urbanoutfitters.com/shop/uo-nail-polish',
Jhannah = 'https://jhannahjewelry.com/collections/nailpolish',
Louboutin = 'http://us.christianlouboutin.com/us_en/pluminette.html',
Orosa = 'https://orosabeauty.com/products/pre-fall-set',
ZOYA = 'https://www.zoya.com/content/category/Zoya_Nail_Polish.html'
)
essie(url$Essie)
?image_palette
####################################################################
####################################################################
setwd("/Users/nancyorgan/Documents/Nail-Polish/")
total = read.csv("total.csv")
show3dPolish(as.character(total$colors[!is.na(total$colors)]), 10)
######################################################################
######################################################################
splitColor = function(color){
parsedColor = data.frame(
r = strtoi(paste0("0x", substr(color, 2,3))),
g = strtoi(paste0("0x", substr(color, 4,5))),
b = strtoi(paste0("0x", substr(color, 6,7))),
colors = color
)
return(parsedColor)
}
show3dPolish = function(colors, clusters){
mydata = splitColor(colors)
mydata$cluster = kmeans(as.matrix(mydata[,1:3]), clusters)$cluster
open3d()
with(mydata, plot3d(r, g, b, type="p", col = colors, radius = 10))
for(i in 1:length(unique(mydata$cluster))){
dat = mydata[mydata$cluster == i,]
plot3d(
ellipse3d(cov(as.matrix(dat[,1:3])),
centre = c(mean(dat$r), mean(dat$g), mean(dat$b))),
col = rgb(mean(dat$r)/255, mean(dat$g)/255, mean(dat$b)/255),
alpha = 0.5,
add = TRUE
)
}
}
show3dnoClusters = function(colors){
mydata = splitColor(colors)
open3d()
with(mydata, plot3d(r, g, b, type="p", col = colors, radius = 20))
}
show3dnoClusters(as.character(total$colors[!is.na(total$colors)]))
show3dnoClusters = function(colors){
mydata = splitColor(colors)
open3d()
with(mydata, plot3d(r, g, b, type="p", col = colors, radius = 40))
}
show3dnoClusters(as.character(total$colors[!is.na(total$colors)]))
show3dPolish(as.character(total$colors[!is.na(total$colors)]), 10)
